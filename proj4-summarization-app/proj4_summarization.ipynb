{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56c7ae30-fd59-45ba-945a-925a94dda116",
   "metadata": {},
   "source": [
    "# 20240310 - Project: Summarization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01db3953-f450-4be7-8a79-07b56019f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643445b5-93a1-43a5-a2e6-688d27fa40b2",
   "metadata": {},
   "source": [
    "## A) Basic Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef78c42-80f3-47f9-a10b-d59033364068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2c743e-4610-447c-a792-647214b8f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = r\"\"\"\n",
    "Mojo combines the usability of Python with the performance of C, unlocking unparalleled programmability \\\n",
    "of AI hardware and extensibility of AI models.\n",
    "Mojo is a new programming language that bridges the gap between research and production \\ \n",
    "by combining the best of Python syntax with systems programming and metaprogramming.\n",
    "With Mojo, you can write portable code that’s faster than C and seamlessly inter-op with the Python ecosystem.\n",
    "When we started Modular, we had no intention of building a new programming language. \\\n",
    "But as we were building our platform with the intent to unify the world’s ML/AI infrastructure, \\\n",
    "we realized that programming across the entire stack was too complicated. Plus, we were writing a \\\n",
    "lot of MLIR by hand and not having a good time.\n",
    "And although accelerators are important, one of the most prevalent and sometimes overlooked \"accelerators\" \\\n",
    "is the host CPU. Nowadays, CPUs have lots of tensor-core-like accelerator blocks and other AI acceleration \\\n",
    "units, but they also serve as the “fallback” for operations that specialized accelerators don’t handle, \\\n",
    "such as data loading, pre- and post-processing, and integrations with foreign systems. \\\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content='You are an expert copywriter with expertise in summarizing documents'),\n",
    "    HumanMessage(content=f'Please provide a short and concise summary of the following text:\\n TEXT: {text}')\n",
    "]\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed9704e-d841-414e-bb78-aa5a9b5f84b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.get_num_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80de1405-a95e-4e7c-bf73-cce67654ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_output = llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d82219-b5e7-4644-a272-8e4f3d3cb0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(summary_output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e856376c-e393-4034-8702-60085e26272e",
   "metadata": {},
   "source": [
    "## Summarizing Using Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538a2201-d31f-43c8-81a5-282a346d16b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "template = '''\n",
    "Write a concise and short summary of the following text:\n",
    "TEXT: `{text}`\n",
    "Translate the summary to {language}.\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['text', 'language'],\n",
    "    template=template\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b17d23-2856-40ab-8a0d-945433aa3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.get_num_tokens(prompt.format(text=text, language='English'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9807ba-e8ef-4556-95cc-cdad6ea8f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "summary = chain.invoke({'text': text, 'language': 'french'})\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6b8155-3a4f-4bd8-97eb-ae8369955c10",
   "metadata": {},
   "source": [
    "## Summarizing using SuffDocumentChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c30dc-59cd-4c80-9ce3-5e2f22311706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab4c10b-8cd8-4b65-829c-c5aaf2ddd00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('files/sj.txt', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# text\n",
    "docs = [Document(page_content=text)]\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf978b83-e56e-4522-8764-7816dbca3b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''Write a concise and short summary of the following text.\n",
    "TEXT: `{text}`\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['text'],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    prompt=prompt,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "output_summary = chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f9b08-27e4-4bd2-b201-9510a816cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_summary['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b97bedb-c3aa-4860-9929-e3ed3d551aa8",
   "metadata": {},
   "source": [
    "## Summarizing Large Documents Using map_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc878d5-cb86-4ae6-800a-04469f0a47cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad82fb63-47bc-44bc-90d0-382a151fc015",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('files/sj.txt', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# text\n",
    "# docs = [Document(page_content=text)]\n",
    "llm = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e24e8fc-497c-41fd-8ea4-b4b09461ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.get_num_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2692983-4b92-45a4-8e4d-6a775feef2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=50)\n",
    "chunks = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5a92f-986c-4ec5-9c97-5ae754eb8e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b4ef7d-d6a0-45b0-aa38-4bb01c937fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type='map_reduce',\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "output_summary = chain.invoke(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c7710-0eaf-48ea-956d-3efc84b52c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(output_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1a6bc77-3602-4d1e-936b-69eb9f9e5875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], template='Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.llm_chain.prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96debf44-902c-451a-8592-8436ea91e962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['text'], template='Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.combine_document_chain.llm_chain.prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478192ac-0f61-48db-a2aa-3d1a0f6716bd",
   "metadata": {},
   "source": [
    "## map_reduce with Custom Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b379f502-b02b-40b6-8982-ebff9f257a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_prompt = '''\n",
    "Write a short and concise summary of the following:\n",
    "Text: `{text}`\n",
    "CONCISE SUMMARY:\n",
    "'''\n",
    "\n",
    "map_prompt_template = PromptTemplate(\n",
    "    input_variables=['text'],\n",
    "    template=map_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9be94fdf-4f50-4f58-9834-0d07d689d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "    combine_prompt = '''\n",
    "Write a concise summary of the following text that covers the key points.\n",
    "Add a title to the summary.\n",
    "Start your summary with an INTRODUCTION PARAGRAPH that gives an overview of the topic \n",
    "FOLLOWED by BULLET POINTS if possible AND end the summary with a CONCLUSION PHRASE.\n",
    "Text: `{text}`\n",
    "'''\n",
    "\n",
    "combine_prompt_template = PromptTemplate(template=combine_prompt, input_variables=['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d5a378e-9a2d-44ff-80e7-095ea86df1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type='map_reduce',\n",
    "    map_prompt=map_prompt_template,\n",
    "    combine_prompt=combine_prompt_template,\n",
    "    verbose=False\n",
    ")\n",
    "output = summary_chain.invoke(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "badd93be-7ac2-421e-9433-53e6d9539d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: \"Lessons from Steve Jobs' Commencement Speech\"\n",
      "\n",
      "Introduction:\n",
      "Steve Jobs shares three impactful stories from his life during a commencement speech, highlighting the importance of following one's passion and living authentically.\n",
      "\n",
      "Key Points:\n",
      "- Story 1: Dropped out of college, followed curiosity, designed Macintosh computer\n",
      "- Story 2: Fired from Apple, found success with NeXT and Pixar\n",
      "- Story 3: Faced death after cancer diagnosis, changed perspective on life\n",
      "- Emphasis on following passion, not settling, living each day to the fullest\n",
      "- Importance of inevitability of death, living authentically, following intuition\n",
      "- Reference to The Whole Earth Catalog, staying hungry and foolish in new beginnings\n",
      "\n",
      "Conclusion:\n",
      "Steve Jobs' stories serve as a reminder to pursue passion, embrace change, and live authentically.\n"
     ]
    }
   ],
   "source": [
    "print(output['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a7857-d32f-46b8-960f-c8afb64e434b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
